{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Find and download a dataset for supervised learning. \n",
    "Loading ecommerce data from kaggle (https://www.kaggle.com/prachi13/customer-analytics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 84: expected 1 fields, saw 2\\nSkipping line 103: expected 1 fields, saw 253\\nSkipping line 104: expected 1 fields, saw 2\\nSkipping line 119: expected 1 fields, saw 3\\nSkipping line 169: expected 1 fields, saw 3\\nSkipping line 188: expected 1 fields, saw 6\\nSkipping line 214: expected 1 fields, saw 4\\nSkipping line 218: expected 1 fields, saw 2\\nSkipping line 231: expected 1 fields, saw 2\\nSkipping line 232: expected 1 fields, saw 2\\nSkipping line 238: expected 1 fields, saw 2\\nSkipping line 241: expected 1 fields, saw 2\\nSkipping line 249: expected 1 fields, saw 4\\nSkipping line 255: expected 1 fields, saw 2\\nSkipping line 260: expected 1 fields, saw 2\\nSkipping line 261: expected 1 fields, saw 2\\nSkipping line 262: expected 1 fields, saw 2\\nSkipping line 263: expected 1 fields, saw 2\\nSkipping line 264: expected 1 fields, saw 2\\nSkipping line 270: expected 1 fields, saw 2\\nSkipping line 271: expected 1 fields, saw 2\\nSkipping line 272: expected 1 fields, saw 2\\nSkipping line 273: expected 1 fields, saw 2\\nSkipping line 280: expected 1 fields, saw 2\\nSkipping line 288: expected 1 fields, saw 4\\nSkipping line 293: expected 1 fields, saw 2\\nSkipping line 296: expected 1 fields, saw 2\\nSkipping line 297: expected 1 fields, saw 2\\nSkipping line 301: expected 1 fields, saw 2\\nSkipping line 321: expected 1 fields, saw 2\\nSkipping line 494: expected 1 fields, saw 6\\nSkipping line 495: expected 1 fields, saw 3\\nSkipping line 507: expected 1 fields, saw 6\\nSkipping line 508: expected 1 fields, saw 6\\nSkipping line 594: expected 1 fields, saw 6\\nSkipping line 603: expected 1 fields, saw 6\\nSkipping line 618: expected 1 fields, saw 6\\nSkipping line 638: expected 1 fields, saw 3\\nSkipping line 647: expected 1 fields, saw 3\\nSkipping line 656: expected 1 fields, saw 3\\nSkipping line 665: expected 1 fields, saw 3\\nSkipping line 674: expected 1 fields, saw 3\\nSkipping line 683: expected 1 fields, saw 3\\nSkipping line 692: expected 1 fields, saw 3\\nSkipping line 701: expected 1 fields, saw 3\\nSkipping line 950: expected 1 fields, saw 7\\nSkipping line 1006: expected 1 fields, saw 2\\nSkipping line 1100: expected 1 fields, saw 2\\nSkipping line 1103: expected 1 fields, saw 2\\nSkipping line 1135: expected 1 fields, saw 2\\nSkipping line 1137: expected 1 fields, saw 2\\nSkipping line 166210: expected 1 fields, saw 2\\nSkipping line 166211: expected 1 fields, saw 3\\nSkipping line 166212: expected 1 fields, saw 3\\nSkipping line 166213: expected 1 fields, saw 3\\nSkipping line 166214: expected 1 fields, saw 3\\nSkipping line 166215: expected 1 fields, saw 3\\nSkipping line 166224: expected 1 fields, saw 3\\nSkipping line 166225: expected 1 fields, saw 3\\nSkipping line 166226: expected 1 fields, saw 3\\nSkipping line 166227: expected 1 fields, saw 3\\nSkipping line 166228: expected 1 fields, saw 3\\nSkipping line 166229: expected 1 fields, saw 3\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;!DOCTYPE html&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;html lang=\"en\" data-color-mode=\"auto\" data-li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;head&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;meta charset=\"utf-8\"&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;link rel=\"dns-prefetch\" href=\"https://githu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                                    <!DOCTYPE html>\n",
       "1  <html lang=\"en\" data-color-mode=\"auto\" data-li...\n",
       "2                                             <head>\n",
       "3                             <meta charset=\"utf-8\">\n",
       "4    <link rel=\"dns-prefetch\" href=\"https://githu..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"https://github.com/beyenidogan/AdvData/blob/main/Project1/\"\n",
    "file_name=\"ecommerce_shipping.csv\"\n",
    "#file_url=folder+file_name\n",
    "file_url=\"https://github.com/beyenidogan/AdvData/blob/main/Project1/ecommerce_shipping.csv\"\n",
    "\n",
    "#def load_shipping_data(path=file_url): \n",
    "#    return pd.read_csv(path)\n",
    "\n",
    "shipping = pd.read_csv(file_url,error_bad_lines=False,header=None)\n",
    "\n",
    "shipping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Divide into a training set and a testing set. In a Jupyter notebook, use scikitlearn to divide you data into training and testing sets. Make sure that the testing and training sets are balanced in terms of target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Explore your training set. In a Jupyter notebook, import your data into a Pandas data frame and use the following pandas functions to explore your data\n",
    "\n",
    "DataFrame.info()\n",
    "DataFrame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Data cleaning. Address any missing values in your training set. Include the code in your Jupyter notebook and create a second, cleaned, version of your dataset. Then apply the same procedure to you test set (if you are putting in replacement values use IMPUTER in scikitlearn).\n",
    "\n",
    "Recall from the Hands on Machine Learning book (p. 60) that some options are\n",
    "“Get rid of the corresponding samples.”\n",
    "“Get rid of the whole attribute (column).”\n",
    "“Set the values to some value (zero, the mean, the median, etc.).”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Visualize the data in your training set. At a minimum, use the following pandas functions to visualize the data in your Jupyter notebook.\n",
    "\n",
    "DataFrame.hist\n",
    "plotting.scatter_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Apply transformations to your data. In your Jupetyr notebook apply, squaring, cubing, logarithmic, and exponentials transformations to two features in your dataset. Plot the histograms and scatter matrices of the resultant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
